{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.llamaindex.ai/en/stable/examples/index_structs/doc_summary/DocSummary/\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.WARNING)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47d34569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ad7cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, get_response_synthesizer\n",
    "from llama_index.core import DocumentSummaryIndex\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39d22855",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_titles = [\"Toronto\", \"Seattle\", \"Chicago\", \"Boston\", \"Houston\"]\n",
    "url = \"https://en.wikipedia.org/w/api.php\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9134ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "for title in wiki_titles:\n",
    "    response = requests.get(\n",
    "        url = url,\n",
    "        params = {\n",
    "            'action': 'query',\n",
    "            'format': 'json',\n",
    "            'titles': title,\n",
    "            'prop': 'extracts',\n",
    "            'explaintext': True,\n",
    "        }\n",
    "    ).json()\n",
    "    page = next(iter(response['query']['pages'].values()))\n",
    "    wiki_text = page['extract']\n",
    "\n",
    "    data_path = Path(\"data\")\n",
    "    if not data_path.exists():\n",
    "        data_path.mkdir()\n",
    "    \n",
    "    with open(data_path / f\"{title}.txt\", \"w\") as f:\n",
    "        f.write(wiki_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eca2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_docs = []\n",
    "for wiki_title in wiki_titles:\n",
    "    docs = SimpleDirectoryReader(\n",
    "        input_files=[f\"data/{wiki_title}.txt\"]\n",
    "    ).load_data()\n",
    "    docs[0].doc_id = wiki_title\n",
    "    city_docs.extend(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40cf813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = GoogleGenAI(model = 'gemini-2.0-flash')\n",
    "splitter = SentenceSplitter(chunk_size=1000, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd2029c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ref_doc_id of node cannot be None when building a document summary index",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     10\u001b[39m google_embed = GoogleGenerativeAIEmbeddings(\n\u001b[32m     11\u001b[39m     model = \u001b[33m'\u001b[39m\u001b[33mmodels/embedding-001\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     12\u001b[39m )\n\u001b[32m     13\u001b[39m embed_model = LangchainEmbedding(GoogleGenerativeAIEmbeddings)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m doc_summary_index = \u001b[43mDocumentSummaryIndex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcity_docs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mgemini\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43membed_model\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_synthesizer\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_synthesizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/LangRAG/venv/lib/python3.13/site-packages/llama_index/core/indices/document_summary/base.py:99\u001b[39m, in \u001b[36mDocumentSummaryIndex.__init__\u001b[39m\u001b[34m(self, nodes, objects, index_struct, llm, embed_model, storage_context, response_synthesizer, summary_query, show_progress, embed_summaries, **kwargs)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28mself\u001b[39m._summary_query = summary_query\n\u001b[32m     97\u001b[39m \u001b[38;5;28mself\u001b[39m._embed_summaries = embed_summaries\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/LangRAG/venv/lib/python3.13/site-packages/llama_index/core/indices/base.py:79\u001b[39m, in \u001b[36mBaseIndex.__init__\u001b[39m\u001b[34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index_struct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     78\u001b[39m     nodes = nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     index_struct = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28mself\u001b[39m._index_struct = index_struct\n\u001b[32m     84\u001b[39m \u001b[38;5;28mself\u001b[39m._storage_context.index_store.add_index_struct(\u001b[38;5;28mself\u001b[39m._index_struct)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/LangRAG/venv/lib/python3.13/site-packages/llama_index/core/indices/base.py:189\u001b[39m, in \u001b[36mBaseIndex.build_index_from_nodes\u001b[39m\u001b[34m(self, nodes, **build_kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Build the index from nodes.\"\"\"\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;28mself\u001b[39m._docstore.add_documents(nodes, allow_update=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbuild_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/LangRAG/venv/lib/python3.13/site-packages/llama_index/core/indices/document_summary/base.py:236\u001b[39m, in \u001b[36mDocumentSummaryIndex._build_index_from_nodes\u001b[39m\u001b[34m(self, nodes, **build_kwargs)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;66;03m# first get doc_id to nodes_dict, generate a summary for each doc_id,\u001b[39;00m\n\u001b[32m    234\u001b[39m \u001b[38;5;66;03m# then build the index struct\u001b[39;00m\n\u001b[32m    235\u001b[39m index_struct = IndexDocumentSummary()\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_add_nodes_to_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_show_progress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m index_struct\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/LangRAG/venv/lib/python3.13/site-packages/llama_index/core/indices/document_summary/base.py:175\u001b[39m, in \u001b[36mDocumentSummaryIndex._add_nodes_to_index\u001b[39m\u001b[34m(self, index_struct, nodes, show_progress)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes:\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m node.ref_doc_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    176\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mref_doc_id of node cannot be None when building a document \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    177\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msummary index\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    178\u001b[39m         )\n\u001b[32m    179\u001b[39m     doc_id_to_nodes[node.ref_doc_id].append(node)\n\u001b[32m    181\u001b[39m summary_node_dict = {}\n",
      "\u001b[31mValueError\u001b[39m: ref_doc_id of node cannot be None when building a document summary index"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    llm = gemini,\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async = True\n",
    ")\n",
    "\n",
    "google_embed = GoogleGenerativeAIEmbeddings(\n",
    "    model = 'models/embedding-001'\n",
    ")\n",
    "embed_model = LangchainEmbedding(GoogleGenerativeAIEmbeddings)\n",
    "doc_summary_index = DocumentSummaryIndex(\n",
    "    city_docs,\n",
    "    llm = gemini,\n",
    "    embed_model = embed_model,\n",
    "    transformations = [splitter],\n",
    "    response_synthesizer = response_synthesizer,\n",
    "    show_progress = True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
